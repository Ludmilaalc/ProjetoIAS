{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyMRpAgzoN6A2778m5N0x2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ludmilaalc/ProjetoIAS/blob/main/cats_dogs_xp_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rCWHcXtHfIO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, tensorflow as tf\n",
        "\n",
        "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    fname=\"cats_and_dogs_filtered.zip\",\n",
        "    origin=url,\n",
        "    extract=False,\n",
        ")\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(\"/content\")\n",
        "\n",
        "base_dir = \"/content/cats_and_dogs_filtered\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
        "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
        "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
        "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
        "\n",
        "for p in [train_cats_dir, train_dogs_dir, validation_cats_dir, validation_dogs_dir]:\n",
        "    print(p, \"->\", len(os.listdir(p)), \"imagens\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDliCqr2yvzf",
        "outputId": "f82e5a71-08e3-4347-931c-ee8e25243090"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "\u001b[1m68606236/68606236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "/content/cats_and_dogs_filtered/train/cats -> 1000 imagens\n",
            "/content/cats_and_dogs_filtered/train/dogs -> 1000 imagens\n",
            "/content/cats_and_dogs_filtered/validation/cats -> 500 imagens\n",
            "/content/cats_and_dogs_filtered/validation/dogs -> 500 imagens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf, zipfile, os\n",
        "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "zip_path = tf.keras.utils.get_file(\"cats_and_dogs_filtered.zip\", origin=url, extract=False)\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z: z.extractall(\"/content\")\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def count_trainable_params(model):\n",
        "    import tensorflow as tf\n",
        "    return int(sum(tf.size(w).numpy() for w in model.trainable_weights))\n",
        "\n",
        "INPUT_SHAPE = (128, 220, 3)\n",
        "base = VGG16(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "# Cabeça tipo VGG: Flatten\n",
        "x = layers.Flatten(name=\"flatten\")(base.output)\n",
        "x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
        "x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
        "out = layers.Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = models.Model(inputs=base.input, outputs=out, name=\"vgg16_xp_style\")\n",
        "print(\"Parâmetros treináveis:\", f\"{count_trainable_params(model):,}\".replace(\",\", \".\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVmn85E7y8cq",
        "outputId": "55362902-baab-42bc-d775-35e15e11ba2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parâmetros treináveis: 81.839.938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Parâmetros treináveis da VGG19\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def count_trainable_params(model):\n",
        "    import tensorflow as tf\n",
        "    return int(sum(tf.size(w).numpy() for w in model.trainable_weights))\n",
        "\n",
        "INPUT_SHAPE = (128, 220, 3)\n",
        "\n",
        "# Base convolucional\n",
        "base = VGG19(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "x = layers.Flatten(name=\"flatten\")(base.output)\n",
        "x = layers.Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
        "x = layers.Dense(4096, activation=\"relu\", name=\"fc2\")(x)\n",
        "out = layers.Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = models.Model(inputs=base.input, outputs=out, name=\"vgg19_xp_style\")\n",
        "\n",
        "print(\"Parâmetros treináveis (VGG19 padrão XP):\",\n",
        "      f\"{count_trainable_params(model):,}\".replace(\",\", \".\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bygwNZ4P0C85",
        "outputId": "a3f9b371-693f-456e-c27b-59ca069b51e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parâmetros treináveis (VGG19 padrão XP): 87.149.634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet152\n",
        "\n",
        "import tensorflow as tf, zipfile\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "def count_trainable_params(model):\n",
        "    return int(sum(tf.size(w).numpy() for w in model.trainable_weights))\n",
        "\n",
        "INPUT_SHAPE = (128, 220, 3)\n",
        "base = ResNet152(include_top=False, weights=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D(name=\"gap\")(base.output)\n",
        "out = layers.Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = models.Model(base.input, out, name=\"resnet152_gap_head\")\n",
        "print(\"Treináveis (ResNet152 + GAP→Dense(2)):\",\n",
        "      f\"{count_trainable_params(model):,}\".replace(\",\", \".\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7oQ9VtU0K-i",
        "outputId": "bac50157-b21b-4a3b-ebdf-0a957082e5cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treináveis (ResNet152 + GAP→Dense(2)): 58.223.618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, glob, cv2, numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "base_dir = \"/content/cats_and_dogs_filtered\"\n",
        "\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
        "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
        "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
        "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
        "\n",
        "# Carregar e redimensionar (220, 128)\n",
        "IMG_W, IMG_H = 220, 128\n",
        "\n",
        "def load_dir(path, label):\n",
        "    X, y = [], []\n",
        "    for fp in sorted(glob.glob(os.path.join(path, \"*\"))):\n",
        "        img = cv2.imread(fp)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (IMG_W, IMG_H))\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "    return X, y\n",
        "\n",
        "Xc_tr, yc_tr = load_dir(train_cats_dir, 0)\n",
        "Xd_tr, yd_tr = load_dir(train_dogs_dir, 1)\n",
        "Xc_va, yc_va = load_dir(validation_cats_dir, 0)\n",
        "Xd_va, yd_va = load_dir(validation_dogs_dir, 1)\n",
        "\n",
        "X = np.array(Xc_tr + Xd_tr + Xc_va + Xd_va, dtype=np.uint8)\n",
        "y = np.array(yc_tr + yd_tr + yc_va + yd_va, dtype=np.int32)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    zoom_range=[0.8, 1.2],\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"reflect\"\n",
        ")\n",
        "\n",
        "Xf = X.astype(\"float32\") / 255.0\n",
        "\n",
        "augmented, labels_aug = [], []\n",
        "generated = 0\n",
        "for xb, yb in datagen.flow(Xf, y, batch_size=64, shuffle=True):\n",
        "    augmented.append(xb)\n",
        "    labels_aug.append(yb)\n",
        "    generated += len(xb)\n",
        "    if generated >= 1000:\n",
        "        break\n",
        "\n",
        "X_aug = np.concatenate(augmented, axis=0)[:1000]\n",
        "y_aug = np.concatenate(labels_aug, axis=0)[:1000]\n",
        "\n",
        "X_all = np.concatenate([Xf, X_aug], axis=0)\n",
        "y_all = np.concatenate([y, y_aug], axis=0)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.30, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "print(\"X_train.shape:\", X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-OzUmuU1Voh",
        "outputId": "f7d8dfbf-7c6c-4ea2-a7d2-80d701cd446f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape: (2800, 128, 220, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2, glob, os\n",
        "\n",
        "base_dir = \"/content/cats_and_dogs_filtered\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
        "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
        "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
        "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
        "\n",
        "\n",
        "IMG_W, IMG_H = 220, 128\n",
        "\n",
        "def load_dir(path, label):\n",
        "    X, y = [], []\n",
        "    for fp in sorted(glob.glob(os.path.join(path, \"*\"))):\n",
        "        img = cv2.imread(fp)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (IMG_W, IMG_H))\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "    return X, y\n",
        "\n",
        "Xc_tr, yc_tr = load_dir(train_cats_dir, 0)\n",
        "Xd_tr, yd_tr = load_dir(train_dogs_dir, 1)\n",
        "Xc_va, yc_va = load_dir(validation_cats_dir, 0)\n",
        "Xd_va, yd_va = load_dir(validation_dogs_dir, 1)\n",
        "\n",
        "X = np.array(Xc_tr + Xd_tr + Xc_va + Xd_va, dtype=np.uint8)\n",
        "y = np.array(yc_tr + yd_tr + yc_va + yd_va, dtype=np.int32)\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    zoom_range=[0.8, 1.2],\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"reflect\"\n",
        ")\n",
        "\n",
        "augmented, labels_aug = [], []\n",
        "generated = 0\n",
        "for xb, yb in datagen.flow(X, y, batch_size=64, shuffle=True):\n",
        "    augmented.append(xb)\n",
        "    labels_aug.append(yb)\n",
        "    generated += len(xb)\n",
        "    if generated >= 1000:\n",
        "        break\n",
        "\n",
        "X_aug = np.concatenate(augmented)[:1000]\n",
        "y_aug = np.concatenate(labels_aug)[:1000]\n",
        "\n",
        "X_all = np.concatenate([X, X_aug], axis=0)\n",
        "y_all = np.concatenate([y, y_aug], axis=0)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.30, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "print(\"y_train.shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcyzhh353ez9",
        "outputId": "4039dabb-def1-4587-eef7-b7087a4c5fac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train.shape: (2800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "def count_trainable_params(layer):\n",
        "    return int(sum(tf.size(w).numpy() for w in layer.trainable_weights))\n",
        "\n",
        "model = VGG19(include_top=False, weights=None, input_shape=(128, 220, 3))\n",
        "\n",
        "conv_layers = [l for l in model.layers if \"conv\" in l.name and hasattr(l, \"kernel\")]\n",
        "\n",
        "layer5 = conv_layers[4]\n",
        "print(\"Camada:\", layer5.name)\n",
        "\n",
        "params = count_trainable_params(layer5)\n",
        "print(\"Parâmetros treináveis (5ª conv da VGG19):\", f\"{params:,}\".replace(\",\", \".\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z06czjTu4Q5G",
        "outputId": "ae269cc4-885b-4148-caeb-df623d66d903"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camada: block3_conv1\n",
            "Parâmetros treináveis (5ª conv da VGG19): 295.168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG19\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "model = VGG19(include_top=False, weights=None, input_shape=(128, 220, 3))\n",
        "\n",
        "conv_layers = [l for l in model.layers if \"conv\" in l.name and hasattr(l, \"kernel\")]\n",
        "\n",
        "layer5 = conv_layers[4]\n",
        "\n",
        "print(\"Camada:\", layer5.name)\n",
        "print(\"Saída (TensorShape):\", layer5.output.shape)\n",
        "\n",
        "out_shape = layer5.output.shape\n",
        "print(\"H×W×C:\", int(out_shape[1]), \"×\", int(out_shape[2]), \"×\", int(out_shape[3]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU87qOD141K5",
        "outputId": "f074547a-da48-4962-b1a1-d5b2090fc701"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camada: block3_conv1\n",
            "Saída (TensorShape): (None, 32, 55, 256)\n",
            "H×W×C: 32 × 55 × 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    zoom_range=[0.8, 1.2],\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"reflect\"\n",
        ")\n",
        "\n",
        "print(\"width_shift_range =\", datagen.width_shift_range)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyHomHi76axh",
        "outputId": "af4cf9ed-12ab-4d8e-8c52-74289d32f012"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width_shift_range = 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qojmr8516l3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}